{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e61ef5-2db0-4df4-965e-5636f0bc0cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3689c2d1-1813-4ef7-8aae-14ab312fbf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce866d4e-2cb5-476e-be01-8dedae71c70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def impute_missing_categories(df, target_column, features=None):\n",
    "    \"\"\"\n",
    "    Impute missing categories in a dataset using multiple classification models.\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame containing data with missing values\n",
    "    target_column: Name of the column with missing categories\n",
    "    features: List of feature columns to use for prediction\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: Original data with imputed values\n",
    "    dict: Model performance results\n",
    "    \"\"\"\n",
    "    # Create a copy of the original dataframe\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # If features not specified, use all columns except target\n",
    "    if features is None:\n",
    "        features = [col for col in df.columns if col != target_column]\n",
    "    \n",
    "    # Split data into sets with and without missing values\n",
    "    train_mask = df[target_column].notna()\n",
    "    train_data = df[train_mask]\n",
    "    missing_data = df[~train_mask]\n",
    "    \n",
    "    # If no missing values, return original data\n",
    "    if len(missing_data) == 0:\n",
    "        return df_copy, {\"message\": \"No missing values found\"}\n",
    "    \n",
    "    # Prepare the data\n",
    "    X_train = train_data[features].copy()\n",
    "    X_missing = missing_data[features].copy()\n",
    "    \n",
    "    # Handle categorical features\n",
    "    categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "    label_encoders = {}\n",
    "    \n",
    "    for column in categorical_features:\n",
    "        label_encoders[column] = LabelEncoder()\n",
    "        X_train[column] = label_encoders[column].fit_transform(X_train[column])\n",
    "        X_missing[column] = label_encoders[column].transform(X_missing[column])\n",
    "    \n",
    "    # Encode target variable\n",
    "    target_encoder = LabelEncoder()\n",
    "    y_train = target_encoder.fit_transform(train_data[target_column])\n",
    "    \n",
    "    # Initialize models\n",
    "    models = {\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        #'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "        'SVM': SVC(probability=True, random_state=42),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=5)\n",
    "    }\n",
    "    \n",
    "    # Dictionary to store results\n",
    "    results = {}\n",
    "    \n",
    "    # Train and evaluate models\n",
    "    for name, model in models.items():\n",
    "        # Cross-validation score\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "        \n",
    "        # Train model on full training data\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions for missing values\n",
    "        y_pred = model.predict(X_missing)\n",
    "        \n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            'cv_mean': cv_scores.mean(),\n",
    "            'cv_std': cv_scores.std(),\n",
    "            'predictions': target_encoder.inverse_transform(y_pred)\n",
    "        }\n",
    "    \n",
    "    # Find best model based on CV score\n",
    "    best_model = max(results.items(), key=lambda x: x[1]['cv_mean'])\n",
    "    \n",
    "    # Fill missing values with predictions from best model\n",
    "    df_copy.loc[~train_mask, target_column] = results[best_model[0]]['predictions']\n",
    "    \n",
    "    return df_copy, results\n",
    "\n",
    "def process_both_datasets(train_df, test_df, target_column, features=None):\n",
    "    \"\"\"\n",
    "    Process both training and test datasets separately for missing value imputation.\n",
    "    \n",
    "    Parameters:\n",
    "    train_df: Training DataFrame\n",
    "    test_df: Test DataFrame\n",
    "    target_column: Name of the column with missing categories\n",
    "    features: List of feature columns to use for prediction\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (Imputed train DataFrame, Imputed test DataFrame, Train results, Test results)\n",
    "    \"\"\"\n",
    "    print(\"Processing training dataset...\")\n",
    "    train_imputed, train_results = impute_missing_categories(\n",
    "        train_df, \n",
    "        target_column, \n",
    "        features\n",
    "    )\n",
    "    \n",
    "    print(\"\\nProcessing test dataset...\")\n",
    "    test_imputed, test_results = impute_missing_categories(\n",
    "        test_df, \n",
    "        target_column, \n",
    "        features\n",
    "    )\n",
    "    \n",
    "    return train_imputed, test_imputed, train_results, test_results\n",
    "\n",
    "def print_imputation_results(train_results, test_results):\n",
    "    \"\"\"Print formatted results of model comparison for both datasets\"\"\"\n",
    "    datasets = [(\"Training Dataset\", train_results), (\"Test Dataset\", test_results)]\n",
    "    \n",
    "    for dataset_name, results in datasets:\n",
    "        print(f\"\\n{dataset_name} Results:\")\n",
    "        print(\"-\" * 50)\n",
    "        if isinstance(results, dict) and \"message\" in results:\n",
    "            print(results[\"message\"])\n",
    "            continue\n",
    "            \n",
    "        for model_name, result in results.items():\n",
    "            print(f\"\\n{model_name}:\")\n",
    "            print(f\"Cross-validation Score: {result['cv_mean']:.4f} (+/- {result['cv_std']*2:.4f})\")\n",
    "            print(f\"Number of predictions made: {len(result['predictions'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffee8328-24e4-40ab-a01f-e3d1ddd883cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StickerDataset(Dataset):\n",
    "    def __init__(self, features, targets=None):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.targets = torch.FloatTensor(targets) if targets is not None else None\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.targets is not None:\n",
    "            return self.features[idx], self.targets[idx]\n",
    "        return self.features[idx]\n",
    "\n",
    "class DeepStickerNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DeepStickerNet, self).__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            \n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604377d1-a6a6-471f-970d-afc4b3e106ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bc664d-1c18-49bd-8b71-0d99d416e367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6585c86-2e82-4463-b53e-691ce085a745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_nn(df, label_encoders=None, scaler=None, is_training=True):\n",
    "    \"\"\"Prepare data for neural network\"\"\"\n",
    "    data = df.copy()\n",
    "    \n",
    "    # Handle categorical variables\n",
    "    cat_cols = ['Brand', 'Material', 'Size','Laptop Compartment', 'Waterproof', 'Style', 'Color']\n",
    "    if label_encoders is None:\n",
    "        label_encoders = {}\n",
    "        for col in cat_cols:\n",
    "            label_encoders[col] = LabelEncoder()\n",
    "            data[col] = label_encoders[col].fit_transform(data[col])\n",
    "    else:\n",
    "        for col in cat_cols:\n",
    "            data[col] = label_encoders[col].transform(data[col])\n",
    "    \n",
    "    # Select features\n",
    "    feature_cols = ['Brand', 'Material', 'Size', 'Compartments', 'Laptop Compartment',\n",
    "       'Waterproof', 'Style', 'Color', 'Weight Capacity (kg)']\n",
    "    \n",
    "    X = data[feature_cols].values\n",
    "    \n",
    "    # Scale features\n",
    "    if scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "    else:\n",
    "        X = scaler.transform(X)\n",
    "    \n",
    "    if is_training:\n",
    "        y = data['Price'].values\n",
    "        return X, y, label_encoders, scaler\n",
    "    return X, label_encoders, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a86d2042-590c-4eb0-8f6f-35cd170c2f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs=50):\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for X_batch, y_batch in tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}'):\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                val_loss += criterion(outputs, y_batch).item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}')\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model.state_dict().copy()\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdbb5b59-1553-4532-a25a-8906d89195e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data = pd.read_csv('playground-series-s5e2/train.csv')\n",
    "test_data = pd.read_csv('playground-series-s5e2/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1941ba78-536c-44fe-af47-4b551dc5bf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300000 entries, 0 to 299999\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   id                    300000 non-null  int64  \n",
      " 1   Brand                 290295 non-null  object \n",
      " 2   Material              291653 non-null  object \n",
      " 3   Size                  293405 non-null  object \n",
      " 4   Compartments          300000 non-null  float64\n",
      " 5   Laptop Compartment    292556 non-null  object \n",
      " 6   Waterproof            292950 non-null  object \n",
      " 7   Style                 292030 non-null  object \n",
      " 8   Color                 290050 non-null  object \n",
      " 9   Weight Capacity (kg)  299862 non-null  float64\n",
      " 10  Price                 300000 non-null  float64\n",
      "dtypes: float64(3), int64(1), object(7)\n",
      "memory usage: 25.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8cbe22ba-f6e4-4d52-b55a-ac31067ee219",
   "metadata": {},
   "source": [
    "train_imputed, test_imputed, train_results, test_results = process_both_datasets(\n",
    "    train_df = train_data, test_df = test_data, \n",
    "    target_column = 'Brand', \n",
    "    features = ['Material', 'Size', 'Compartments', 'Laptop Compartment', 'Waterproof', 'Style', 'Color', 'Weight Capacity (kg)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bb0b74-4920-4bc8-8969-0e8402153251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c1706e-36e7-40d6-b54b-e07c871329d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7b0bd55-ac21-4a7d-adb2-03a915319c26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|█████████████████████████████████████████████████████████████████| 3985/3985 [00:22<00:00, 176.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 2533.9770, Val Loss = 1521.9274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|█████████████████████████████████████████████████████████████████| 3985/3985 [00:25<00:00, 154.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 1525.4779, Val Loss = 1521.5919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|█████████████████████████████████████████████████████████████████| 3985/3985 [00:25<00:00, 155.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 1524.8511, Val Loss = 1523.9452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|█████████████████████████████████████████████████████████████████| 3985/3985 [00:25<00:00, 156.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 1524.5991, Val Loss = 1520.6549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|█████████████████████████████████████████████████████████████████| 3985/3985 [00:25<00:00, 154.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss = 1524.3745, Val Loss = 1522.5002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|█████████████████████████████████████████████████████████████████| 3985/3985 [00:26<00:00, 150.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss = 1524.3612, Val Loss = 1520.8489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|█████████████████████████████████████████████████████████████████| 3985/3985 [00:27<00:00, 147.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss = 1524.2212, Val Loss = 1520.8471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|█████████████████████████████████████████████████████████████████| 3985/3985 [00:25<00:00, 157.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss = 1524.1230, Val Loss = 1522.2078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|█████████████████████████████████████████████████████████████████| 3985/3985 [00:25<00:00, 156.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss = 1524.1096, Val Loss = 1521.0246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:25<00:00, 153.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss = 1523.8657, Val Loss = 1520.8008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:25<00:00, 154.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss = 1523.7621, Val Loss = 1520.7031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:26<00:00, 151.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss = 1523.5219, Val Loss = 1521.6785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:25<00:00, 155.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss = 1523.4547, Val Loss = 1520.6493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:25<00:00, 154.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss = 1523.4755, Val Loss = 1521.7363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:26<00:00, 152.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss = 1523.5928, Val Loss = 1520.8234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:26<00:00, 152.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss = 1523.3260, Val Loss = 1521.0946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:25<00:00, 154.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss = 1523.4017, Val Loss = 1521.9218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:25<00:00, 154.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss = 1523.3547, Val Loss = 1521.4220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:25<00:00, 155.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss = 1523.0527, Val Loss = 1521.7923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:26<00:00, 151.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss = 1522.8407, Val Loss = 1521.0594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:25<00:00, 155.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train Loss = 1523.0605, Val Loss = 1522.0773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:25<00:00, 153.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train Loss = 1522.8686, Val Loss = 1521.2741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:25<00:00, 156.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Train Loss = 1522.8911, Val Loss = 1521.2392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:25<00:00, 155.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train Loss = 1522.7195, Val Loss = 1521.2861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:24<00:00, 161.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Train Loss = 1522.6258, Val Loss = 1521.8224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:26<00:00, 148.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Train Loss = 1522.6420, Val Loss = 1521.1355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:25<00:00, 155.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Train Loss = 1522.4709, Val Loss = 1521.0460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:24<00:00, 164.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Train Loss = 1522.3338, Val Loss = 1521.0362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:23<00:00, 168.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Train Loss = 1522.1768, Val Loss = 1524.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:23<00:00, 167.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Train Loss = 1522.1996, Val Loss = 1521.6145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:24<00:00, 166.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Train Loss = 1522.2035, Val Loss = 1521.0774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:23<00:00, 168.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Train Loss = 1521.9228, Val Loss = 1522.1757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:20<00:00, 197.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Train Loss = 1522.0653, Val Loss = 1522.0417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:17<00:00, 223.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Train Loss = 1521.9598, Val Loss = 1521.0318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:18<00:00, 210.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Train Loss = 1521.9407, Val Loss = 1522.5051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:18<00:00, 218.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Train Loss = 1521.7858, Val Loss = 1522.9361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:18<00:00, 218.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Train Loss = 1521.7423, Val Loss = 1521.4333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:19<00:00, 204.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Train Loss = 1521.7751, Val Loss = 1521.9909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:18<00:00, 211.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Train Loss = 1521.5380, Val Loss = 1522.8265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:18<00:00, 216.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Train Loss = 1521.5414, Val Loss = 1522.0468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:17<00:00, 222.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Train Loss = 1520.9495, Val Loss = 1523.8479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:17<00:00, 232.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Train Loss = 1521.1682, Val Loss = 1522.3474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:17<00:00, 234.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: Train Loss = 1521.1082, Val Loss = 1522.1764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:18<00:00, 217.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Train Loss = 1521.0764, Val Loss = 1521.9599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:17<00:00, 229.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Train Loss = 1521.0380, Val Loss = 1522.2785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:19<00:00, 204.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss = 1520.9861, Val Loss = 1524.1158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:21<00:00, 184.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train Loss = 1520.7073, Val Loss = 1521.9525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:21<00:00, 185.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Train Loss = 1520.6640, Val Loss = 1522.4135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:21<00:00, 183.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Train Loss = 1520.4549, Val Loss = 1522.4629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50: 100%|████████████████████████████████████████████████████████████████| 3985/3985 [00:22<00:00, 180.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Train Loss = 1520.7796, Val Loss = 1522.4254\n"
     ]
    }
   ],
   "source": [
    "# def main():\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load data\n",
    "train_data = pd.read_csv('playground-series-s5e2/train.csv')\n",
    "test_data = pd.read_csv('playground-series-s5e2/test.csv')\n",
    "#\n",
    "train_data = train_data.ffill()\n",
    "test_data = test_data.ffill()\n",
    "#\n",
    "# Impute missing values\n",
    "# train_data, test_data = impute_missing_values(train_data, test_data)\n",
    "\n",
    "# Prepare data\n",
    "X_train, y_train, label_encoders, scaler = prepare_data_for_nn(train_data, is_training=True)\n",
    "X_test, _, _ = prepare_data_for_nn(test_data, label_encoders, scaler, is_training=False)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = StickerDataset(X_train, y_train)\n",
    "train_size = int(0.85 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "\n",
    "# Initialize model\n",
    "model = DeepStickerNet(input_dim=X_train.shape[1]).to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-6)\n",
    "\n",
    "# Train model\n",
    "best_model_state = train_model(model, train_loader, val_loader, criterion, optimizer, device)\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(best_model_state)\n",
    "\n",
    "# Make predictions\n",
    "model.eval()\n",
    "test_dataset = StickerDataset(X_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        predictions.extend(outputs.cpu().numpy())\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_data['id'],\n",
    "    'Price': predictions\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3640a9a0-83d5-490a-8e89-9965aae6b827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95050895-9ccf-4bb0-a42d-a11f095c4332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to submission/deep_learning_predictions_20250209_012403.csv\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "file_name = f\"submission/deep_learning_predictions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "submission.to_csv(file_name, index=False)\n",
    "print(\"Predictions saved to {}\".format(file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72907198-80ce-4da0-b7df-bf31e58e034e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
